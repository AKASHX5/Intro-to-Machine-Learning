{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.1,3.5,1.4,0.2,Iris-setosa\\\n",
      "4.9,3,1.4,0.2,Iris-setosa\\\n",
      "4.7,3.2,1.3,0.2,Iris-setosa\\\n",
      "4.6,3.1,1.5,0.2,Iris-setosa\\\n",
      "5,3.6,1.4,0.2,Iris-setosa\\\n",
      "5.4,3.9,1.7,0.4,Iris-setosa\\\n",
      "4.6,3.4,1.4,0.3,Iris-setosa\\\n",
      "5,3.4,1.5,0.2,Iris-setosa\\\n",
      "4.4,2.9,1.4,0.2,Iris-setosa\\\n",
      "4.9,3.1,1.5,0.1,Iris-setosa\\\n",
      "5.4,3.7,1.5,0.2,Iris-setosa\\\n",
      "4.8,3.4,1.6,0.2,Iris-setosa\\\n",
      "4.8,3,1.4,0.1,Iris-setosa\\\n",
      "4.3,3,1.1,0.1,Iris-setosa\\\n",
      "5.8,4,1.2,0.2,Iris-setosa\\\n",
      "5.7,4.4,1.5,0.4,Iris-setosa\\\n",
      "5.4,3.9,1.3,0.4,Iris-setosa\\\n",
      "5.1,3.5,1.4,0.3,Iris-setosa\\\n",
      "5.7,3.8,1.7,0.3,Iris-setosa\\\n",
      "5.1,3.8,1.5,0.3,Iris-setosa\\\n",
      "5.4,3.4,1.7,0.2,Iris-setosa\\\n",
      "5.1,3.7,1.5,0.4,Iris-setosa\\\n",
      "4.6,3.6,1,0.2,Iris-setosa\\\n",
      "5.1,3.3,1.7,0.5,Iris-setosa\\\n",
      "4.8,3.4,1.9,0.2,Iris-setosa\\\n",
      "5,3,1.6,0.2,Iris-setosa\\\n",
      "5,3.4,1.6,0.4,Iris-setosa\\\n",
      "5.2,3.5,1.5,0.2,Iris-setosa\\\n",
      "5.2,3.4,1.4,0.2,Iris-setosa\\\n",
      "4.7,3.2,1.6,0.2,Iris-setosa\\\n",
      "4.8,3.1,1.6,0.2,Iris-setosa\\\n",
      "5.4,3.4,1.5,0.4,Iris-setosa\\\n",
      "5.2,4.1,1.5,0.1,Iris-setosa\\\n",
      "5.5,4.2,1.4,0.2,Iris-setosa\\\n",
      "4.9,3.1,1.5,0.1,Iris-setosa\\\n",
      "5,3.2,1.2,0.2,Iris-setosa\\\n",
      "5.5,3.5,1.3,0.2,Iris-setosa\\\n",
      "4.9,3.1,1.5,0.1,Iris-setosa\\\n",
      "4.4,3,1.3,0.2,Iris-setosa\\\n",
      "5.1,3.4,1.5,0.2,Iris-setosa\\\n",
      "5,3.5,1.3,0.3,Iris-setosa\\\n",
      "4.5,2.3,1.3,0.3,Iris-setosa\\\n",
      "4.4,3.2,1.3,0.2,Iris-setosa\\\n",
      "5,3.5,1.6,0.6,Iris-setosa\\\n",
      "5.1,3.8,1.9,0.4,Iris-setosa\\\n",
      "4.8,3,1.4,0.3,Iris-setosa\\\n",
      "5.1,3.8,1.6,0.2,Iris-setosa\\\n",
      "4.6,3.2,1.4,0.2,Iris-setosa\\\n",
      "5.3,3.7,1.5,0.2,Iris-setosa\\\n",
      "5,3.3,1.4,0.2,Iris-setosa\\\n",
      "7,3.2,4.7,1.4,Iris-versicolor\\\n",
      "6.4,3.2,4.5,1.5,Iris-versicolor\\\n",
      "6.9,3.1,4.9,1.5,Iris-versicolor\\\n",
      "5.5,2.3,4,1.3,Iris-versicolor\\\n",
      "6.5,2.8,4.6,1.5,Iris-versicolor\\\n",
      "5.7,2.8,4.5,1.3,Iris-versicolor\\\n",
      "6.3,3.3,4.7,1.6,Iris-versicolor\\\n",
      "4.9,2.4,3.3,1,Iris-versicolor\\\n",
      "6.6,2.9,4.6,1.3,Iris-versicolor\\\n",
      "5.2,2.7,3.9,1.4,Iris-versicolor\\\n",
      "5,2,3.5,1,Iris-versicolor\\\n",
      "5.9,3,4.2,1.5,Iris-versicolor\\\n",
      "6,2.2,4,1,Iris-versicolor\\\n",
      "6.1,2.9,4.7,1.4,Iris-versicolor\\\n",
      "5.6,2.9,3.6,1.3,Iris-versicolor\\\n",
      "6.7,3.1,4.4,1.4,Iris-versicolor\\\n",
      "5.6,3,4.5,1.5,Iris-versicolor\\\n",
      "5.8,2.7,4.1,1,Iris-versicolor\\\n",
      "6.2,2.2,4.5,1.5,Iris-versicolor\\\n",
      "5.6,2.5,3.9,1.1,Iris-versicolor\\\n",
      "5.9,3.2,4.8,1.8,Iris-versicolor\\\n",
      "6.1,2.8,4,1.3,Iris-versicolor\\\n",
      "6.3,2.5,4.9,1.5,Iris-versicolor\\\n",
      "6.1,2.8,4.7,1.2,Iris-versicolor\\\n",
      "6.4,2.9,4.3,1.3,Iris-versicolor\\\n",
      "6.6,3,4.4,1.4,Iris-versicolor\\\n",
      "6.8,2.8,4.8,1.4,Iris-versicolor\\\n",
      "6.7,3,5,1.7,Iris-versicolor\\\n",
      "6,2.9,4.5,1.5,Iris-versicolor\\\n",
      "5.7,2.6,3.5,1,Iris-versicolor\\\n",
      "5.5,2.4,3.8,1.1,Iris-versicolor\\\n",
      "5.5,2.4,3.7,1,Iris-versicolor\\\n",
      "5.8,2.7,3.9,1.2,Iris-versicolor\\\n",
      "6,2.7,5.1,1.6,Iris-versicolor\\\n",
      "5.4,3,4.5,1.5,Iris-versicolor\\\n",
      "6,3.4,4.5,1.6,Iris-versicolor\\\n",
      "6.7,3.1,4.7,1.5,Iris-versicolor\\\n",
      "6.3,2.3,4.4,1.3,Iris-versicolor\\\n",
      "5.6,3,4.1,1.3,Iris-versicolor\\\n",
      "5.5,2.5,4,1.3,Iris-versicolor\\\n",
      "5.5,2.6,4.4,1.2,Iris-versicolor\\\n",
      "6.1,3,4.6,1.4,Iris-versicolor\\\n",
      "5.8,2.6,4,1.2,Iris-versicolor\\\n",
      "5,2.3,3.3,1,Iris-versicolor\\\n",
      "5.6,2.7,4.2,1.3,Iris-versicolor\\\n",
      "5.7,3,4.2,1.2,Iris-versicolor\\\n",
      "5.7,2.9,4.2,1.3,Iris-versicolor\\\n",
      "6.2,2.9,4.3,1.3,Iris-versicolor\\\n",
      "5.1,2.5,3,1.1,Iris-versicolor\\\n",
      "5.7,2.8,4.1,1.3,Iris-versicolor\\\n",
      "6.3,3.3,6,2.5,Iris-virginica\\\n",
      "5.8,2.7,5.1,1.9,Iris-virginica\\\n",
      "7.1,3,5.9,2.1,Iris-virginica\\\n",
      "6.3,2.9,5.6,1.8,Iris-virginica\\\n",
      "6.5,3,5.8,2.2,Iris-virginica\\\n",
      "7.6,3,6.6,2.1,Iris-virginica\\\n",
      "4.9,2.5,4.5,1.7,Iris-virginica\\\n",
      "7.3,2.9,6.3,1.8,Iris-virginica\\\n",
      "6.7,2.5,5.8,1.8,Iris-virginica\\\n",
      "7.2,3.6,6.1,2.5,Iris-virginica\\\n",
      "6.5,3.2,5.1,2,Iris-virginica\\\n",
      "6.4,2.7,5.3,1.9,Iris-virginica\\\n",
      "6.8,3,5.5,2.1,Iris-virginica\\\n",
      "5.7,2.5,5,2,Iris-virginica\\\n",
      "5.8,2.8,5.1,2.4,Iris-virginica\\\n",
      "6.4,3.2,5.3,2.3,Iris-virginica\\\n",
      "6.5,3,5.5,1.8,Iris-virginica\\\n",
      "7.7,3.8,6.7,2.2,Iris-virginica\\\n",
      "7.7,2.6,6.9,2.3,Iris-virginica\\\n",
      "6,2.2,5,1.5,Iris-virginica\\\n",
      "6.9,3.2,5.7,2.3,Iris-virginica\\\n",
      "5.6,2.8,4.9,2,Iris-virginica\\\n",
      "7.7,2.8,6.7,2,Iris-virginica\\\n",
      "6.3,2.7,4.9,1.8,Iris-virginica\\\n",
      "6.7,3.3,5.7,2.1,Iris-virginica\\\n",
      "7.2,3.2,6,1.8,Iris-virginica\\\n",
      "6.2,2.8,4.8,1.8,Iris-virginica\\\n",
      "6.1,3,4.9,1.8,Iris-virginica\\\n",
      "6.4,2.8,5.6,2.1,Iris-virginica\\\n",
      "7.2,3,5.8,1.6,Iris-virginica\\\n",
      "7.4,2.8,6.1,1.9,Iris-virginica\\\n",
      "7.9,3.8,6.4,2,Iris-virginica\\\n",
      "6.4,2.8,5.6,2.2,Iris-virginica\\\n",
      "6.3,2.8,5.1,1.5,Iris-virginica\\\n",
      "6.1,2.6,5.6,1.4,Iris-virginica\\\n",
      "7.7,3,6.1,2.3,Iris-virginica\\\n",
      "6.3,3.4,5.6,2.4,Iris-virginica\\\n",
      "6.4,3.1,5.5,1.8,Iris-virginica\\\n",
      "6,3,4.8,1.8,Iris-virginica\\\n",
      "6.9,3.1,5.4,2.1,Iris-virginica\\\n",
      "6.7,3.1,5.6,2.4,Iris-virginica\\\n",
      "6.9,3.1,5.1,2.3,Iris-virginica\\\n",
      "5.8,2.7,5.1,1.9,Iris-virginica\\\n",
      "6.8,3.2,5.9,2.3,Iris-virginica\\\n",
      "6.7,3.3,5.7,2.5,Iris-virginica\\\n",
      "6.7,3,5.2,2.3,Iris-virginica\\\n",
      "6.3,2.5,5,1.9,Iris-virginica\\\n",
      "6.5,3,5.2,2,Iris-virginica\\\n",
      "6.2,3.4,5.4,2.3,Iris-virginica\\\n",
      "5.9,3,5.1,1.8,Iris-virginica\\\n",
      "},,,,\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('iris.data.csv','rb') as csvfile:\n",
    "    lines=csv.reader(csvfile)\n",
    "    for rows in lines:\n",
    "        print ','.join(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random \n",
    "def loadDataset(filename,split,trainingSet=[],testSet=[]):\n",
    "    with open(filename,'rb')as csvfile:\n",
    "        lines=csv.reader(csvfile)\n",
    "        dataset=list(lines)\n",
    "        for x in range (len(dataset)-1):\n",
    "            for y in range(4):\n",
    "                dataset[x][y]=float(dataset[x][y])\n",
    "            if random.random()<split:\n",
    "                trainingSet.append(dataset[x])\n",
    "            else: \n",
    "                testSet.append(dataset[y])\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 98\n",
      "Test: 52\n"
     ]
    }
   ],
   "source": [
    "trainingSet=[]\n",
    "testSet=[]\n",
    "loadDataset('iris.data.csv',0.66,trainingSet,testSet)\n",
    "print 'Train: ' + repr(len(trainingSet))\n",
    "print 'Test: ' + repr(len(testSet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def euclideanDistance(instance1,instance2,length):\n",
    "    distance=0\n",
    "    for x in range(length):\n",
    "        distance += pow((instance1[x]-instance2[x]),2)\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 0.0\n"
     ]
    }
   ],
   "source": [
    "data1=[2,3,4,2,'a']\n",
    "data2=[4,7,5,3,'b']\n",
    "\n",
    "distance= euclideanDistance(data1,data1,4)\n",
    "print 'Distance: ' + repr(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator \n",
    "def getNeighbors(trainingSet,testInstance,k):\n",
    "    distance=[]\n",
    "    length=len(testInstance)-1\n",
    "    for x in range (len(trainingSet)):\n",
    "        dist=euclideanDistance(testInstance,trainingSet[x],length)\n",
    "        distance.append((trainingSet[x],dist))\n",
    "    distance.sort(key=operator.itemgetter(1))\n",
    "    neighbors=[]\n",
    "    for x in range(k):\n",
    "        neighbors.append(distance[x][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 4, 4, 'b']]\n"
     ]
    }
   ],
   "source": [
    "trainSet=[[2,2,2,'a'],[4,4,4,'b']]\n",
    "testInstance=[5,5,5]\n",
    "k=1\n",
    "neighbors=getNeighbors(trainSet,testInstance,k)\n",
    "print (neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getResponse(neighbors):\n",
    "    classVotes={}\n",
    "    for x in range(len(neighbors)):\n",
    "        response=neighbors[x][-1]\n",
    "        if response in classVotes:\n",
    "            classVotes[response] +=1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "        sortedVotes = sorted(classVotes.iteritems(),key=operator.itemgetter(1),reverse=True)\n",
    "        return sortedVotes[0][0]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "neighbors=[[1,1,1,'a'],[2,2,2,'a'],[3,3,3,'b']]\n",
    "response=getResponse(neighbors)\n",
    "print (response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAccuracy(testSet,predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] is predictions[x]:\n",
    "            correct +=1\n",
    "    return (correct/float(len(testSet)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.6666666667\n"
     ]
    }
   ],
   "source": [
    "testSet = [[1,1,1,'a'],[2,2,2,'a'],[3,3,3,'b']]\n",
    "predictions = ['a','a','a']\n",
    "accuracy= getAccuracy(testSet,predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 99\n",
      "Test: 51\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "> predicted='Iris-setosa\\\\', actual='Iris-setosa\\\\'\n",
      "Accuracy: 0.0%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #prepareData\n",
    "    trainingSet=[]\n",
    "    testSet=[]\n",
    "    split=0.67\n",
    "    loadDataset('iris.data.csv',split,trainingSet,testSet)\n",
    "    print 'Train: ' + repr(len(trainingSet))\n",
    "    print 'Test: ' + repr(len(testSet))\n",
    "    \n",
    "    #generate Predictions\n",
    "    predictions=[]\n",
    "    k=3\n",
    "    for x in range(len(testSet)):\n",
    "        neighbors=getNeighbors(trainingSet,testSet[x],k)\n",
    "        result=getResponse(neighbors)\n",
    "        predictions.append(result)\n",
    "        print('> predicted=' +repr(result)+', actual=' +repr(testSet[x][-1]))\n",
    "    accuracy= getAccuracy(testSet,predictions)\n",
    "    print('Accuracy: ' +repr(accuracy) + '%')\n",
    "    \n",
    "    \n",
    "main()\n",
    "\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-cdfec08fac30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-54-cdfec08fac30>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# random_state = 1 is just a seed to permit reproducibility of the train/test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0miris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iris.data.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainingSet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# reformat train/test datasets for convenience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import Counter\n",
    " \n",
    "# 1) given two data points, calculate the euclidean distance between them\n",
    "def get_distance(data1, data2):\n",
    "    points = zip(data1, data2)\n",
    "    diffs_squared_distance = [pow(a - b, 2) for (a, b) in points]\n",
    "    return math.sqrt(sum(diffs_squared_distance))\n",
    " \n",
    "# 2) given a training set and a test instance, use getDistance to calculate all pairwise distances\n",
    "def get_neighbours(training_set, test_instance, k):\n",
    "    distances = [_get_tuple_distance(training_instance, test_instance) for training_instance in training_set]\n",
    "    # index 1 is the calculated distance between training_instance and test_instance\n",
    "    sorted_distances = sorted(distances, key=itemgetter(1))\n",
    "    # extract only training instances\n",
    "    sorted_training_instances = [tuple[0] for tuple in sorted_distances]\n",
    "    # select first k elements\n",
    "    return sorted_training_instances[:k]\n",
    " \n",
    "def _get_tuple_distance(training_instance, test_instance):\n",
    "    return (training_instance, get_distance(test_instance, training_instance[0]))\n",
    " \n",
    "# 3) given an array of nearest neighbours for a test case, tally up their classes to vote on test case class\n",
    "def get_majority_vote(neighbours):\n",
    "    # index 1 is the class\n",
    "    classes = [neighbour[1] for neighbour in neighbours]\n",
    "    count = Counter(classes)\n",
    "    return count.most_common()[0][0] \n",
    " \n",
    "# setting up main executable method\n",
    "def main():\n",
    "    trainingSet=[]\n",
    "    testSet=[]\n",
    "    split=0.67\n",
    "    # load the data and create the training and test sets\n",
    "    # random_state = 1 is just a seed to permit reproducibility of the train/test split\n",
    "    iris = loadDataset('iris.data.csv',split,trainingSet,testSet)\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(iris.data, iris.target, test_size=0.4, random_state=1)\n",
    " \n",
    "    # reformat train/test datasets for convenience\n",
    "    train = np.array(zip(X_train,y_train))\n",
    "    test = np.array(zip(X_test, y_test))\n",
    " \n",
    "    # generate predictions\n",
    "    predictions = []\n",
    " \n",
    "    # let's arbitrarily set k equal to 5, meaning that to predict the class of new instances,\n",
    "    k = 5\n",
    " \n",
    "    # for each instance in the test set, get nearest neighbours and majority vote on predicted class\n",
    "    for x in range(len(X_test)):\n",
    " \n",
    "            print 'Classifying test instance number ' + str(x) + \":\",\n",
    "            neighbours = get_neighbours(training_set=train, test_instance=test[x][0], k=5)\n",
    "            majority_vote = get_majority_vote(neighbours)\n",
    "            predictions.append(majority_vote)\n",
    "            print 'Predicted label=' + str(majority_vote) + ', Actual label=' + str(test[x][1])\n",
    " \n",
    "    # summarize performance of the classification\n",
    "    print '\\nThe overall accuracy of the model is: ' + str(accuracy_score(y_test, predictions)) + \"\\n\"\n",
    "    report = classification_report(y_test, predictions, target_names = iris.target_names)\n",
    "    print 'A detailed classification report: \\n\\n' + report\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
